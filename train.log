--------------------------------------
some config:
data_dir = ./data
output_dir = ./output
embedding_path = ./embedding/hlbl-embeddings-scaled.EMBEDDING_SIZE=50.txt
word_dim = 50
model_name = CNN
mode = 1
seed = 5782
cuda = 0
epoch = 20
dropout = 0.5
batch_size = 128
lr = 0.001
max_len = 100
pos_dis = 50
pos_dim = 5
hidden_size = 100
filter_num = 200
window = 3
L2_decay = 1e-05
device = cuda:0
model_dir = ./output/CNN
--------------------------------------
start to load data ...
finish!
--------------------------------------
CNN(
  (word_embedding): Embedding(246123, 50)
  (pos1_embedding): Embedding(103, 5)
  (pos2_embedding): Embedding(103, 5)
  (conv): Conv2d(1, 200, kernel_size=(3, 60), stride=(1, 1), padding=(1, 0))
  (maxpool): MaxPool2d(kernel_size=(100, 1), stride=(100, 1), padding=0, dilation=1, ceil_mode=False)
  (tanh): Tanh()
  (relu): ReLU()
  (dropout): Dropout(p=0.3, inplace=False)
  (linear): Linear(in_features=200, out_features=100, bias=True)
  (dense): Linear(in_features=100, out_features=19, bias=True)
)
traning model parameters:
word_embedding.weight :  torch.Size([246123, 50])
pos1_embedding.weight :  torch.Size([103, 5])
pos2_embedding.weight :  torch.Size([103, 5])
conv.weight :  torch.Size([200, 1, 3, 60])
conv.bias :  torch.Size([200])
linear.weight :  torch.Size([100, 200])
linear.bias :  torch.Size([100])
dense.weight :  torch.Size([19, 100])
dense.bias :  torch.Size([19])
--------------------------------------
start to train the model ...
[001] train_loss: 2.270 | dev_loss: 2.271 | micro f1 on dev: 0.4320 >>> save models!
[002] train_loss: 1.542 | dev_loss: 1.550 | micro f1 on dev: 0.5004 >>> save models!
[003] train_loss: 1.128 | dev_loss: 1.233 | micro f1 on dev: 0.6435 >>> save models!
[004] train_loss: 0.875 | dev_loss: 1.073 | micro f1 on dev: 0.7128 >>> save models!
[005] train_loss: 0.644 | dev_loss: 0.983 | micro f1 on dev: 0.7406 >>> save models!
[006] train_loss: 0.471 | dev_loss: 0.922 | micro f1 on dev: 0.7641 >>> save models!
[007] train_loss: 0.341 | dev_loss: 0.904 | micro f1 on dev: 0.7687 >>> save models!
[008] train_loss: 0.254 | dev_loss: 0.926 | micro f1 on dev: 0.7735 >>> save models!
[009] train_loss: 0.176 | dev_loss: 0.921 | micro f1 on dev: 0.7819 >>> save models!
[010] train_loss: 0.122 | dev_loss: 0.934 | micro f1 on dev: 0.7794 
[011] train_loss: 0.087 | dev_loss: 0.966 | micro f1 on dev: 0.7827 >>> save models!
[012] train_loss: 0.061 | dev_loss: 1.003 | micro f1 on dev: 0.7816 
[013] train_loss: 0.045 | dev_loss: 1.013 | micro f1 on dev: 0.7753 
[014] train_loss: 0.033 | dev_loss: 1.044 | micro f1 on dev: 0.7805 
[015] train_loss: 0.023 | dev_loss: 1.084 | micro f1 on dev: 0.7862 >>> save models!
[016] train_loss: 0.017 | dev_loss: 1.111 | micro f1 on dev: 0.7827 
[017] train_loss: 0.015 | dev_loss: 1.179 | micro f1 on dev: 0.7889 >>> save models!
[018] train_loss: 0.010 | dev_loss: 1.187 | micro f1 on dev: 0.7785 
[019] train_loss: 0.008 | dev_loss: 1.190 | micro f1 on dev: 0.7850 
[020] train_loss: 0.005 | dev_loss: 1.206 | micro f1 on dev: 0.7755 
--------------------------------------
start test ...
test_loss: 1.179 | micro f1 on test:  0.7889
